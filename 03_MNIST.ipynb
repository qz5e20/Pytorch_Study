{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d4fc54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#识别手写系统MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef78ef7",
   "metadata": {},
   "source": [
    "输入图片，然后模型处理，之后识别结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b757f616",
   "metadata": {},
   "source": [
    "# 过程\n",
    "定义超参数,构建transforms，对图像做变换,下载数据集,\n",
    "构建网络模型,\n",
    "定义训练方法,\n",
    "定义测试方法,\n",
    "开始训练模型，输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "788700a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7b8b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义超参数\n",
    "BATCH_SIZE = 32 #分批次，减少电脑负担\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")#决定是gpu训练是cpu训练\n",
    "EPOCHS = 10  #训练的轮次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f62881",
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建pipeline，对图像进行处理\n",
    "pipeline = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,))    #过拟合时降低模型复杂度\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "762a086f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "#下载加载数据\n",
    "from torch.utils.data import DataLoader\n",
    "#下载\n",
    "train_set = datasets.MNIST(\"data_mnist\", train=True, download=True, transform=pipeline) \n",
    "\n",
    "test_set = datasets.MNIST(\"data_mnist\", train=False, download=True, transform=pipeline)\n",
    "#\n",
    "train_loader = DataLoader(train_set, batch_size= BATCH_SIZE, shuffle=True) #shuffle是打乱的意思\n",
    "\n",
    "test_loader = DataLoader(test_set, batch_size= BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ed8d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看，显示图片\n",
    "with open(r\"C:\\Users\\user\\DL\\Torch_study\\data_mnist\\MNIST\\raw\\train-images-idx3-ubyte\",\"rb\") as f:\n",
    "    file=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe16e896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 24, 24, 24, 294, 310, 373, 38, 358, 597, 583, 295, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 48, 54, 148, 340, 368, 595, 595, 595, 595, 595, 549, 370, 595, 578, 405, 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 73, 568, 595, 595, 595, 595, 595, 595, 595, 595, 593, 147, 130, 130, 86, 57, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 537, 595, 595, 595, 595, 595, 408, 386, 583, 577, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 342, 263, 595, 595, 517, 17, 0, 67, 340, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 1, 340, 595, 144, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 313, 595, 400, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 400, 595, 112, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 53, 577, 549, 352, 264, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 129, 576, 595, 595, 281, 37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 69, 390, 595, 595, 336, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 22, 147, 594, 595, 391, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 585, 595, 585, 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 70, 304, 387, 595, 595, 519, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 57, 328, 553, 595, 595, 595, 592, 386, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 276, 545, 595, 595, 595, 595, 513, 120, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 102, 531, 595, 595, 595, 595, 408, 129, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 369, 537, 595, 595, 595, 595, 405, 128, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 85, 370, 550, 595, 595, 595, 595, 580, 307, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 310, 595, 595, 595, 530, 309, 306, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "image1 = [int(str(item).encode('ascii'),16) for item in file[16 : 16+784]]\n",
    "print(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85399ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image1_np = np.array(image1, dtype=np.uint8).reshape(28,28,1)\n",
    "\n",
    "print(image1_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b40e0ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"MNIST.jpg\",image1_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abfc8b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建网络\n",
    "class Digital(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #卷积层一般作为滤波器 \n",
    "        self.conv1 = nn.Conv2d(1,10,5) # 1代表灰度图片的通道，10表示输出通道。5是kernal卷积核\n",
    "        self.conv2 = nn.Conv2d(10,20,3) #10是输入通道，20输出，3是kernal\n",
    "        #官方代码有Dropout，丢了一部分，nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(20*10*10, 500) #全连接层，第一个是输入通道，第二个是输出通道\n",
    "        self.fc2 = nn.Linear(500, 10) #输出10个概率？\n",
    "    def forward(self,x):\n",
    "        input_size = x.size(0) #batch_size x1 x 28x 28\n",
    "        x = self.conv1(x) #输入 x1 x 28x 28， 输出是batch*10*24*24\n",
    "        #10是输出通道，24是28-5+1=24\n",
    "        x = F.relu(x) #激活函数 在所有隐藏层支架加入激活函数，让输出是非线性，让表达能力更强，\n",
    "        #softmax函数多分类，sigmoid二分类\n",
    "        x = F.max_pool2d(x,2,2) #池化层，将图片压缩，降采样\n",
    "        #最大池化层 重点看最大的区域\n",
    "        #这里输入是 10*24*24 输出是 10*12*12\n",
    "        \n",
    "        x = self.conv2(x) #10*12*12 输出变成 20*10*10   10是因为12-kernal（3）+1\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #官方用的flatten，拉平，torch.flatten\n",
    "        x = x.view(input_size,-1) #拉伸， -1表示自动计算维度 其实应该是20*10*10=2000\n",
    "        \n",
    "        #送入全连接层\n",
    "        x = self.fc1(x) #输入2000 输出500\n",
    "        x = F.relu(x) #保持shape不变\n",
    "        \n",
    "        x = self.fc2(x) #最后得到10的输出\n",
    "        \n",
    "        output = F.log_softmax(x,dim=1) #计算分类后，每个数字的概率值，损失函数\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6023f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义优化器\n",
    "model = Digital().to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a360d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练方法\n",
    "def train_model(model, device, train_loader,optimizer, epoch):\n",
    "    #模型训练\n",
    "    model.train()\n",
    "    for batch_index,(data,target) in enumerate(train_loader): #enumerate可以给出下标\n",
    "        #部署到devices\n",
    "        data, target = data.to(device),target.to(device)\n",
    "        #梯度初始化\n",
    "        optimizer.zero_grad()\n",
    "        #预测，训练后的结果\n",
    "        output = model(data)\n",
    "        #计算损失，即比较预测和真实结果\n",
    "        loss = F.cross_entropy(output,target) #交叉熵针对多分类任务，\n",
    "        #找到概率值最大的下标,后面可以用来计算准确率\n",
    "        pred = output.max(1,keepdim=True)#pred = output.argmax(dim=1)\n",
    "        #反向传播\n",
    "        loss.backward()\n",
    "        #参数优化\n",
    "        optimizer.step()\n",
    "        if batch_index % 3000 == 0:\n",
    "            print(\"Train Epoch: {} \\t Loss: {:.6f}\".format(epoch,loss.item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f15ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义测试方法\n",
    "def test_model(model,device,test_loader):\n",
    "    #模型验证\n",
    "    model.eval()\n",
    "    #正确率\n",
    "    correct = 0.0\n",
    "    #测试损失\n",
    "    test_loss =0.0\n",
    "    with torch.no_grad(): #不会计算梯度，也不会进行反向传播\n",
    "        for data,target in test_loader:\n",
    "            #部署到device上\n",
    "            data,target = data.to(device), target.to(device)\n",
    "            #测试数据\n",
    "            output = model(data)\n",
    "            #计算测试损失\n",
    "            test_loss += F.cross_entropy(output, target).item()\n",
    "            #找到概率最大的下标\n",
    "            pred = output.max(1,keepdim=True)[1] #0是值，1是索引\n",
    "            #pred = torch.max(output,dim=1)\n",
    "            #pred = output.argmax(dim=1)\n",
    "            #累计正确的值\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print(\"Test_average_Loss: {:.4f},Accuracy:{:.3f}\\n\".format(\n",
    "            test_loss, 100.0*correct/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2450b1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 \t Loss: 2.294851\n",
      "Test_average_Loss: 0.0018,Accuracy:98.100\n",
      "\n",
      "Train Epoch: 2 \t Loss: 0.037167\n",
      "Test_average_Loss: 0.0012,Accuracy:98.920\n",
      "\n",
      "Train Epoch: 3 \t Loss: 0.147214\n",
      "Test_average_Loss: 0.0013,Accuracy:98.690\n",
      "\n",
      "Train Epoch: 4 \t Loss: 0.002908\n",
      "Test_average_Loss: 0.0015,Accuracy:98.550\n",
      "\n",
      "Train Epoch: 5 \t Loss: 0.002023\n",
      "Test_average_Loss: 0.0014,Accuracy:98.710\n",
      "\n",
      "Train Epoch: 6 \t Loss: 0.001296\n",
      "Test_average_Loss: 0.0013,Accuracy:98.980\n",
      "\n",
      "Train Epoch: 7 \t Loss: 0.000015\n",
      "Test_average_Loss: 0.0014,Accuracy:98.960\n",
      "\n",
      "Train Epoch: 8 \t Loss: 0.000789\n",
      "Test_average_Loss: 0.0016,Accuracy:98.910\n",
      "\n",
      "Train Epoch: 9 \t Loss: 0.000088\n",
      "Test_average_Loss: 0.0017,Accuracy:98.790\n",
      "\n",
      "Train Epoch: 10 \t Loss: 0.000186\n",
      "Test_average_Loss: 0.0013,Accuracy:99.060\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#调用方法\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "    train_model(model,DEVICE,train_loader,optimizer,epoch)\n",
    "    test_model(model,DEVICE,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b3a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
